FROM ubuntu:20.04

WORKDIR /root/
RUN apt-get update -y && apt-get upgrade -y && DEBIAN_FRONTEND=noninteractive apt-get install -y openjdk-8-jre build-essential cmake wget git libunwind-dev openssh-server sshpass vim
RUN DEBIAN_FRONTEND=noninteractive apt-get install -y python3 python3-pip python-is-python3
RUN python -m pip install scikit-learn tqdm pyyaml pandas numpy pyarrow
RUN python -m pip install nlp_primitives[complete] featuretools==1.16.0 evalml bokeh>=2.4.2
RUN apt install -y graphviz

#azureml
RUN python -m pip install torch==1.11.0
#RUN python -m pip install  https://aka.ms/automl-resources/packages/en_core_web_sm-2.1.0.tar.gz

# ssh setup
RUN sed -i 's/#Port 22/Port 12349/g' /etc/ssh/sshd_config
RUN sed -i 's/#   Port 22/    Port 12349/g' /etc/ssh/ssh_config
RUN echo 'PermitRootLogin yes' >> /etc/ssh/sshd_config

# install spark
RUN python -m pip install jupyter
RUN wget -qO- https://archive.apache.org/dist/spark/spark-3.2.1/spark-3.2.1-bin-hadoop3.2.tgz | tar xvz -C /home/
COPY spark/spark-env.sh .
ADD spark/spark-defaults.conf /home/spark-3.2.1-bin-hadoop3.2/conf/spark-defaults.conf
ADD spark/start_spark_service.sh /home/start_spark_service.sh
RUN chmod +x /home/start_spark_service.sh
ADD start_jupyter.sh /home/start_jupyter.sh
RUN chmod +x /home/start_jupyter.sh
RUN echo "source ~/spark-env.sh" >> /etc/bash.bashrc

# install hadoop
RUN if [ "${install_hadoop}" = "True" ]; then wget -qO- https://archive.apache.org/dist/hadoop/common/hadoop-3.3.1/hadoop-3.3.1.tar.gz | tar xvz -C /home/; fi
RUN if [ "${install_hadoop}" = "True" ]; then echo "export CLASSPATH=$CLASSPATH:`/home/hadoop-3.3.1/bin/hdfs classpath --glob`" >> /etc/bash.bashrc; fi
RUN echo "root:docker" | chpasswd

ENTRYPOINT [""]